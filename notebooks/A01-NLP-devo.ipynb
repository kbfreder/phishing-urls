{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import logging\n",
    "import pickle\n",
    "import feather\n",
    "\n",
    "import pandas as pd\n",
    "from docopt import docopt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# project_dir = os.path.dirname(os.path.dirname(os.path.abspath(os.path.curdir)))\n",
    "project_dir = os.path.dirname(os.path.abspath(os.path.curdir))\n",
    "new_path = os.path.join(project_dir, 'src')\n",
    "sys.path.append(new_path)\n",
    "\n",
    "from model import pipeline as p\n",
    "import util as u\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "filename = 'train_df.pkl'\n",
    "file_path = os.path.join('../../data/interim', filename)\n",
    "save_path = '../../data/processed/'\n",
    "\n",
    "print('Loading data...')\n",
    "train_df = feather.read_dataframe('../data/processed/train_df.feather')\n",
    "print('Data loaded!')\n",
    "\n",
    "# define stop words\n",
    "stopwords = set(ENGLISH_STOP_WORDS).union(set(('com', 'net', 'gov', 'edu', 'http', 'https', 'www')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_urls = train_df['url']\n",
    "X_path = train_df['path']\n",
    "\n",
    "target = 'label'\n",
    "y = train_df['label']\n",
    "enc = LabelEncoder()\n",
    "y_enc = enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 1565431\n"
     ]
    }
   ],
   "source": [
    "# The token pattern excludes \"words\" that start with a digit or\n",
    "# an underscore (_).\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1),\n",
    "                             token_pattern='(?u)\\\\b[a-zA-Z]\\\\w+\\\\b',\n",
    "                             stop_words=stopwords)\n",
    "tfidf_output = vectorizer.fit_transform(X_path)\n",
    "tfidf_features = vectorizer.get_feature_names()\n",
    "print('Total number of features: {}'.format(len(tfidf_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_res = u.assess_model_only(mnb, tfidf_output, y_enc, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0               9.988630e-01\n",
       "Recall-0 (Specificty)     9.999989e-01\n",
       "F1score-0                 9.994306e-01\n",
       "Precision-1               7.940476e-01\n",
       "Recall-1 (Sensitivity)    3.997994e-03\n",
       "F1score-1                 7.951334e-03\n",
       "TN                        1.488186e+06\n",
       "FN                        1.694000e+03\n",
       "FP                        1.600000e+00\n",
       "TP                        6.800000e+00\n",
       "AUC                       8.873018e-01\n",
       "Accuracy                  9.988619e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most important terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_class_prob_list = list(zip(tfidf_features, mnb.feature_log_prob_[0, :]))\n",
    "pos_class_prob_list = list(zip(tfidf_features, mnb.feature_log_prob_[1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_class_prob_list.sort(key=lambda x: x[1], reverse=True)\n",
    "pos_class_prob_list.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_class_prob_sorted = mnb.feature_log_prob_[0, :].argsort()\n",
    "# pos_class_prob_sorted = mnb.feature_log_prob_[1, :].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important terms for benign class:\n",
      "['html', 'php', 'txt', 'robots', 'index', 'tag', 'news', 'products', 'en', 'product']\n",
      "\n",
      "Most important terms for phishing class\n",
      "['php', 'login', 'wp', 'index', 'bankofamerica', 'includes', 'html', 'content', 'signin', 'myaccount']\n"
     ]
    }
   ],
   "source": [
    "print('Most important terms for benign class:')\n",
    "print([x[0] for x in neg_class_prob_list[:10]])\n",
    "print('')\n",
    "print('Most important terms for phishing class')\n",
    "# print(np.take(tfidf_features, pos_class_prob_sorted[:10]))\n",
    "print([x[0] for x in pos_class_prob_list[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling TF-IDF on urls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0               9.988584e-01\n",
       "Recall-0 (Specificty)     9.999970e-01\n",
       "F1score-0                 9.994274e-01\n",
       "Precision-1               0.000000e+00\n",
       "Recall-1 (Sensitivity)    0.000000e+00\n",
       "F1score-1                 0.000000e+00\n",
       "TN                        1.488183e+06\n",
       "FN                        1.700800e+03\n",
       "FP                        4.400000e+00\n",
       "TP                        0.000000e+00\n",
       "AUC                       5.026199e-01\n",
       "Accuracy                  9.988555e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,1),\n",
    "                             token_pattern='(?u)\\\\b[a-zA-Z]\\\\w+\\\\b',\n",
    "                             stop_words=stopwords)\n",
    "tfidf_output = vectorizer.fit_transform(X_path)\n",
    "tfidf_features = vectorizer.get_feature_names()\n",
    "mnb_res = u.assess_model_only(mnb, tfidf_output, y_enc, n=5)\n",
    "mnb_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,1),\n",
    "                             token_pattern='(?u)\\\\b[a-zA-Z]\\\\w+\\\\b',\n",
    "                             stop_words=stopwords)\n",
    "cv_output = vectorizer.fit_transform(X_urls)\n",
    "cv_features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 1850497\n"
     ]
    }
   ],
   "source": [
    "print('Total number of features: {}'.format(len(cv_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0               9.992449e-01\n",
       "Recall-0 (Specificty)     9.994575e-01\n",
       "F1score-0                 9.993512e-01\n",
       "Precision-1               4.167435e-01\n",
       "Recall-1 (Sensitivity)    3.391339e-01\n",
       "F1score-1                 3.739356e-01\n",
       "TN                        1.487380e+06\n",
       "FN                        1.124000e+03\n",
       "FP                        8.074000e+02\n",
       "TP                        5.768000e+02\n",
       "AUC                       9.568612e-01\n",
       "Accuracy                  9.987037e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_res = u.assess_model_only(mnb, cv_output, y_enc, n=5)\n",
    "mnb_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constrain tokens returns to reduce # of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 308153\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,1),\n",
    "                             token_pattern='(?u)\\\\b[a-zA-Z]\\\\w+\\\\b',\n",
    "                             stop_words=stopwords, \n",
    "                            max_df = 0.5,\n",
    "                            min_df = 5)\n",
    "cv_output = vectorizer.fit_transform(X_urls)\n",
    "cv_features = vectorizer.get_feature_names()\n",
    "\n",
    "print('Total number of features: {}'.format(len(cv_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0               9.992974e-01\n",
       "Recall-0 (Specificty)     9.988764e-01\n",
       "F1score-0                 9.990868e-01\n",
       "Precision-1               2.817344e-01\n",
       "Recall-1 (Sensitivity)    3.854645e-01\n",
       "F1score-1                 3.255104e-01\n",
       "TN                        1.486516e+06\n",
       "FN                        1.045200e+03\n",
       "FP                        1.672200e+03\n",
       "TP                        6.556000e+02\n",
       "AUC                       9.483653e-01\n",
       "Accuracy                  9.981761e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_res = u.assess_model_only(mnb, cv_output, y_enc, n=5)\n",
    "mnb_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-score is worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More proper way of cross-validating: perform CountVect inside cross-val -- but this takes longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,1),\n",
    "                             token_pattern='(?u)\\\\b[a-zA-Z]\\\\w+\\\\b',\n",
    "                             stop_words=stopwords,)\n",
    "# cv_output = vectorizer.fit_transform(X_urls)\n",
    "# cv_features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_res = u.assess_model(vectorizer, mnb, X_urls, y_enc, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0               9.991810e-01\n",
       "Recall-0 (Specificty)     9.999413e-01\n",
       "F1score-0                 9.995610e-01\n",
       "Precision-1               8.463615e-01\n",
       "Recall-1 (Sensitivity)    2.828077e-01\n",
       "F1score-1                 4.239280e-01\n",
       "TN                        1.488100e+06\n",
       "FN                        1.219800e+03\n",
       "FP                        8.740000e+01\n",
       "TP                        4.810000e+02\n",
       "AUC                       9.436324e-01\n",
       "Accuracy                  9.991226e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUTURE WORK**:\n",
    "- Try performing `CountVectorizer` on *paths* instead of full urls. Then fit to Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,1),\n",
    "                             token_pattern='(?u)\\\\b[a-zA-Z]\\\\w+\\\\b',\n",
    "                             stop_words=stopwords)\n",
    "cv_output = vectorizer.fit_transform(X_path)\n",
    "cv_features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 1565431\n"
     ]
    }
   ],
   "source": [
    "print('Total number of features: {}'.format(len(cv_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision-0               9.989953e-01\n",
       "Recall-0 (Specificty)     9.993016e-01\n",
       "F1score-0                 9.991484e-01\n",
       "Precision-1               1.648966e-01\n",
       "Recall-1 (Sensitivity)    1.206497e-01\n",
       "F1score-1                 1.393413e-01\n",
       "TN                        1.487148e+06\n",
       "FN                        1.495600e+03\n",
       "FP                        1.039400e+03\n",
       "TP                        2.052000e+02\n",
       "AUC                       9.014331e-01\n",
       "Accuracy                  9.982985e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_res = u.assess_model_only(mnb, cv_output, y_enc, n=5)\n",
    "mnb_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

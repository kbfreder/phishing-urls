{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:59:29.693704Z",
     "start_time": "2019-12-06T20:59:26.828848Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import gzip\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import os, sys\n",
    "import tldextract\n",
    "import collections\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "\n",
    "# had to add:\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:59:31.293615Z",
     "start_time": "2019-12-06T20:59:31.273601Z"
    }
   },
   "outputs": [],
   "source": [
    "storage_folder = '../data/index_paths/'\n",
    "\n",
    "cc_indexes = [os.path.join(storage_folder, f) for f in os.listdir(storage_folder) \n",
    "                    if os.path.isfile(os.path.join(storage_folder, f))]\n",
    "\n",
    "first_file = cc_indexes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:59:33.918454Z",
     "start_time": "2019-12-06T20:59:33.913453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/index_paths/cc-index.paths'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:59:40.576079Z",
     "start_time": "2019-12-06T20:59:40.568079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cc-index.paths', 'cc-index.paths.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(storage_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:59:58.068135Z",
     "start_time": "2019-12-06T20:59:58.060136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/index_paths/cc-index.paths', '../data/index_paths/cc-index.paths.gz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions from parse_cc_index.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:00:08.242121Z",
     "start_time": "2019-12-06T21:00:08.192117Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_every_line(fname, max_lines=-1):\n",
    "    lines = []\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            lines.append(l)\n",
    "            if i>max_lines and max_lines>0:\n",
    "                break\n",
    "    return lines\n",
    "\n",
    "def reporthook(count, block_size, total_size):\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = int(progress_size / (1024 * duration))\n",
    "    percent = int(count * block_size * 100 / total_size)\n",
    "    sys.stdout.write(\"\\r...%d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
    "                    (percent, progress_size / (1024 * 1024), speed, duration))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def save(url, filename):\n",
    "    urllib.request.urlretrieve(url, filename, reporthook)\n",
    "\n",
    "def process_index_file_line(line):\n",
    "    assert type(line)==str\n",
    "    \n",
    "    try:\n",
    "        lst = line.replace('\\n','').split()\n",
    "        ts = lst[1]\n",
    "        data = json.loads(line.replace('\\n','').split(ts)[-1].strip())\n",
    "    except:\n",
    "        return ()\n",
    "    \n",
    "    if data['status'] != '200':\n",
    "        return ()\n",
    "    else:\n",
    "        try:\n",
    "            language = data['languages']\n",
    "        except:\n",
    "            language = 'none'\n",
    "            \n",
    "        try:\n",
    "            _tldextract = tldextract.extract(data['url'])\n",
    "            tup = (ts,\n",
    "                   data['url'],\n",
    "                   _tldextract.suffix,\n",
    "                   data['length'],\n",
    "                   data['offset'],\n",
    "                   data['filename'],\n",
    "                   language              \n",
    "                )\n",
    "            return tup\n",
    "        except:\n",
    "            return ()\n",
    "\n",
    "def list_multiprocessing(param_lst,\n",
    "                         func,\n",
    "                         **kwargs):\n",
    "    \n",
    "    workers = kwargs.pop('workers')\n",
    "\n",
    "    with Pool(workers) as p:\n",
    "        apply_lst = [([params], func, i, kwargs) for i,params in enumerate(param_lst)]\n",
    "        result = list(tqdm(p.imap(_apply_lst, apply_lst), total=len(apply_lst)))\n",
    "\n",
    "    # lists do not need such sorting, but this can be useful later\n",
    "    result=sorted(result,key=lambda x:x[0])\n",
    "    return [_[1] for _ in result]\n",
    "\n",
    "\n",
    "def _apply_lst(args):\n",
    "    params, func, num, kwargs = args\n",
    "    return num, func(*params,**kwargs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:00:12.703519Z",
     "start_time": "2019-12-06T21:00:12.679519Z"
    }
   },
   "outputs": [],
   "source": [
    "# def process_index_file(file_name):\n",
    "#     print('Unzipping index file ... ')\n",
    "    \n",
    "# #     df_name = file_name.replace('.gz','.feather')\n",
    "#     df_name = file_name.split('/')[-1].replace('.gz', '.feather')    \n",
    "#     file_unzipped = file_name.split('.gz')[0]\n",
    "\n",
    "#     with gzip.open(file_name, 'rb') as f_in:\n",
    "#         with open(file_unzipped, 'wb') as f_out:\n",
    "#             shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "#     lines = read_every_line(file_unzipped, 1e8)\n",
    "\n",
    "#     print('{} lines extracted'.format(len(lines)))\n",
    "    \n",
    "#     print('Pre-processing index lines ... ')\n",
    "#     out = list_multiprocessing(lines,\n",
    "#                                process_index_file_line,\n",
    "#                                workers=8)\n",
    "    \n",
    "#     # filter our blank lines\n",
    "#     out =  [_ for _ in out if _ != ()]\n",
    "\n",
    "#     print('Index pre-processed ... ')\n",
    "\n",
    "#     print('Processing index dataframe ... ')\n",
    "\n",
    "#     ts_list       = [_[0] for _ in out]\n",
    "#     url_list      = [_[1] for _ in out]\n",
    "#     tld           = [_[2] for _ in out]\n",
    "#     length_list   = [_[3] for _ in out]\n",
    "#     offset_list   = [_[4] for _ in out]\n",
    "#     warc_list     = [_[5] for _ in out]\n",
    "#     language_list = [_[6] for _ in out]\n",
    "\n",
    "#     cols = ['ts','url','tld','length','offset','warc','language']\n",
    "#     df = pd.DataFrame(data={\n",
    "#         'ts':ts_list,\n",
    "#         'url':url_list,\n",
    "#         'tld':tld,\n",
    "#         'length':length_list,\n",
    "#         'offset':offset_list,\n",
    "#         'warc':warc_list,\n",
    "#         'language':language_list}\n",
    "#                       ,columns=cols)\n",
    "\n",
    "#     df = df[df.language=='rus']\n",
    "#     df['wet'] = df.warc.apply(lambda x: x.replace('/warc/','/wet/').replace('.warc.','.warc.wet.'))\n",
    "#     df['wet'] = df['wet'].apply(lambda x: file_prefix + x)\n",
    "\n",
    "#     print('Index dataframe is ready ... ')\n",
    "    \n",
    "#     os.remove(file_name) \n",
    "#     os.remove(file_unzipped) \n",
    "\n",
    "#     print('Files removed ... ')\n",
    "    \n",
    "#     df = df.dropna().drop_duplicates().reset_index(drop=True)\n",
    "#     df.to_feather(df_name)\n",
    "    \n",
    "#     print('Df saved ... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-06T20:48:55.714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping index file ... \n",
      "302 lines extracted\n",
      "Pre-processing index lines ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/302 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "process_index_file(first_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't use Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:03:28.288351Z",
     "start_time": "2019-12-06T21:03:28.266362Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_index_file(file_name):\n",
    "    '''Will currently only process first line'''\n",
    "    print('Unzipping index file ... ')\n",
    "    \n",
    "#     df_name = file_name.replace('.gz','.feather')\n",
    "    df_name = file_name.split('/')[-1].replace('.gz', '.feather')    \n",
    "    file_unzipped = file_name.split('.gz')[0]\n",
    "\n",
    "    with gzip.open(file_name, 'rb') as f_in:\n",
    "        with open(file_unzipped, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    lines = read_every_line(file_unzipped, 1e8)\n",
    "\n",
    "    print('{} lines extracted'.format(len(lines)))\n",
    "    \n",
    "    print('Pre-processing index lines ... ')\n",
    "#     out = list_multiprocessing(lines,\n",
    "#                                process_index_file_line,\n",
    "#                                workers=8)\n",
    "    \n",
    "    out = process_index_file_line(lines[0])\n",
    "    \n",
    "    # filter our blank lines\n",
    "    out =  [_ for _ in out if _ != ()]\n",
    "\n",
    "    print('Index pre-processed ... ')\n",
    "\n",
    "    print('Processing index dataframe ... ')\n",
    "\n",
    "    ts_list       = [_[0] for _ in out]\n",
    "    url_list      = [_[1] for _ in out]\n",
    "    tld           = [_[2] for _ in out]\n",
    "    length_list   = [_[3] for _ in out]\n",
    "    offset_list   = [_[4] for _ in out]\n",
    "    warc_list     = [_[5] for _ in out]\n",
    "    language_list = [_[6] for _ in out]\n",
    "\n",
    "    cols = ['ts','url','tld','length','offset','warc','language']\n",
    "    df = pd.DataFrame(data={\n",
    "                            'ts':ts_list,\n",
    "                            'url':url_list,\n",
    "                            'tld':tld,\n",
    "                            'length':length_list,\n",
    "                            'offset':offset_list,\n",
    "                            'warc':warc_list,\n",
    "                            'language':language_list}\n",
    "                      ,columns=cols)\n",
    "\n",
    "#     df = df[df.language=='rus']\n",
    "    df['wet'] = df.warc.apply(lambda x: x.replace('/warc/','/wet/').replace('.warc.','.warc.wet.'))\n",
    "    df['wet'] = df['wet'].apply(lambda x: file_prefix + x)\n",
    "\n",
    "    print('Index dataframe is ready ... ')\n",
    "    \n",
    "#     os.remove(file_name) \n",
    "#     os.remove(file_unzipped) \n",
    "#     print('Files removed ... ')\n",
    "    \n",
    "    df = df.dropna().drop_duplicates().reset_index(drop=True)\n",
    "    df.to_feather(df_name)\n",
    "    \n",
    "    print('Df saved ... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:03:31.423119Z",
     "start_time": "2019-12-06T21:03:31.418123Z"
    }
   },
   "outputs": [],
   "source": [
    "first_file = cc_indexes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:03:31.805103Z",
     "start_time": "2019-12-06T21:03:31.799099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/index_paths/cc-index.paths.gz'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:03:37.769999Z",
     "start_time": "2019-12-06T21:03:37.344701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping index file ... \n",
      "302 lines extracted\n",
      "Pre-processing index lines ... \n",
      "Index pre-processed ... \n",
      "Processing index dataframe ... \n",
      "Index dataframe is ready ... \n",
      "Df saved ... \n"
     ]
    }
   ],
   "source": [
    "process_index_file(first_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:04:26.880444Z",
     "start_time": "2019-12-06T21:04:26.857460Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_feather('cc-index.paths.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:04:34.500694Z",
     "start_time": "2019-12-06T21:04:34.477696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>url</th>\n",
       "      <th>tld</th>\n",
       "      <th>length</th>\n",
       "      <th>offset</th>\n",
       "      <th>warc</th>\n",
       "      <th>language</th>\n",
       "      <th>wet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ts, url, tld, length, offset, warc, language, wet]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouble-shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:05:23.772057Z",
     "start_time": "2019-12-06T21:05:23.768057Z"
    }
   },
   "outputs": [],
   "source": [
    "file_name = first_file\n",
    "# df_name = file_name.replace('.gz','.feather')\n",
    "file_unzipped = file_name.split('.gz')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:05:32.132532Z",
     "start_time": "2019-12-06T21:05:32.117664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 lines extracted\n"
     ]
    }
   ],
   "source": [
    "lines = read_every_line(file_unzipped, 1e8)\n",
    "print('{} lines extracted'.format(len(lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:05:37.037911Z",
     "start_time": "2019-12-06T21:05:37.030909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc-index/collections/CC-MAIN-2019-47/indexes/cdx-00000.gz\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:05:41.342878Z",
     "start_time": "2019-12-06T21:05:41.335883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc-index/collections/CC-MAIN-2019-47/indexes/cdx-00001.gz\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:07:04.044041Z",
     "start_time": "2019-12-06T21:07:04.038036Z"
    }
   },
   "outputs": [],
   "source": [
    "    # cc_indexes = [_.replace('\\n','') for _ in cc_indexes]\n",
    "lines = [line.replace('\\n','') for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:07:06.347819Z",
     "start_time": "2019-12-06T21:07:06.341550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc-index/collections/CC-MAIN-2019-47/indexes/cdx-00000.gz'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:07:53.905496Z",
     "start_time": "2019-12-06T21:07:53.896499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cdx-00000.gz'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:09:39.707256Z",
     "start_time": "2019-12-06T21:09:39.702248Z"
    }
   },
   "outputs": [],
   "source": [
    "cc_index = lines[0]\n",
    "cc_index_file = cc_index.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:08:10.969441Z",
     "start_time": "2019-12-06T21:08:10.965440Z"
    }
   },
   "outputs": [],
   "source": [
    "file_dict = collections.OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:08:47.848998Z",
     "start_time": "2019-12-06T21:08:47.846012Z"
    }
   },
   "outputs": [],
   "source": [
    "file_prefix = 'https://commoncrawl.s3.amazonaws.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:09:53.707673Z",
     "start_time": "2019-12-06T21:09:53.703671Z"
    }
   },
   "outputs": [],
   "source": [
    "file_dict[os.path.join(storage_folder, cc_index_file)] = file_prefix + cc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:09:57.118866Z",
     "start_time": "2019-12-06T21:09:57.109882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('../data/index_paths/cdx-00000.gz',\n",
       "              'https://commoncrawl.s3.amazonaws.com/cc-index/collections/CC-MAIN-2019-47/indexes/cdx-00000.gz')])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:13:16.701852Z",
     "start_time": "2019-12-06T21:13:16.695853Z"
    }
   },
   "outputs": [],
   "source": [
    "file_dict = collections.OrderedDict()\n",
    "\n",
    "# iterate over the index files\n",
    "for i, cc_index in enumerate(lines[:10]):\n",
    "#     if i>75:\n",
    "    cc_index_file = cc_index.split('/')[-1]\n",
    "    file_dict[os.path.join(storage_folder, cc_index_file)] = file_prefix + cc_index\n",
    "#     else:\n",
    "#         pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:13:28.284756Z",
     "start_time": "2019-12-06T21:13:28.264753Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_index_file(file_name):\n",
    "    print('Unzipping index file ... ')\n",
    "    \n",
    "    df_name = file_name.replace('.gz','.feather')\n",
    "    file_unzipped = file_name.split('.gz')[0]\n",
    "\n",
    "    with gzip.open(file_name, 'rb') as f_in:\n",
    "        with open(file_unzipped, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    lines = read_every_line(file_unzipped,\n",
    "                            1e8)\n",
    "\n",
    "    print('{} lines extracted'.format(len(lines)))\n",
    "    \n",
    "    print('Pre-processing index lines ... ')\n",
    "    out = list_multiprocessing(lines,\n",
    "                               process_index_file_line,\n",
    "                               workers=8)\n",
    "    \n",
    "    # filter our blank lines\n",
    "    out =  [_ for _ in out if _ != ()]\n",
    "\n",
    "    print('Index pre-processed ... ')\n",
    "\n",
    "    print('Processing index dataframe ... ')\n",
    "\n",
    "    ts_list       = [_[0] for _ in out]\n",
    "    url_list      = [_[1] for _ in out]\n",
    "    tld           = [_[2] for _ in out]\n",
    "    length_list   = [_[3] for _ in out]\n",
    "    offset_list   = [_[4] for _ in out]\n",
    "    warc_list     = [_[5] for _ in out]\n",
    "    language_list = [_[6] for _ in out]\n",
    "\n",
    "    cols = ['ts','url','tld','length','offset','warc','language']\n",
    "    df = pd.DataFrame(data={\n",
    "        'ts':ts_list,\n",
    "        'url':url_list,\n",
    "        'tld':tld,\n",
    "        'length':length_list,\n",
    "        'offset':offset_list,\n",
    "        'warc':warc_list,\n",
    "        'language':language_list}\n",
    "                      ,columns=cols)\n",
    "\n",
    "#     df = df[df.language=='rus']\n",
    "    df['wet'] = df.warc.apply(lambda x: x.replace('/warc/','/wet/').replace('.warc.','.warc.wet.'))\n",
    "    df['wet'] = df['wet'].apply(lambda x: file_prefix + x)\n",
    "\n",
    "    print('Index dataframe is ready ... ')\n",
    "    \n",
    "    os.remove(file_name) \n",
    "    os.remove(file_unzipped) \n",
    "\n",
    "    print('Files removed ... ')\n",
    "    \n",
    "    df = df.dropna().drop_duplicates().reset_index(drop=True)\n",
    "    df.to_feather(df_name)\n",
    "    \n",
    "    print('Df saved ... ')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-06T21:13:40.533Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING INDEX FILE [0]/[10] ...\n",
      "Downloading an index file ../data/index_paths/cdx-00000.gz ...\n",
      "...100%, 659 MB, 3094 KB/s, 218 seconds passedUnzipping index file ... \n",
      "9815044 lines extracted\n",
      "Pre-processing index lines ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                      | 0/9815044 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for i,(file_name, url) in enumerate(tqdm(file_dict.items())):\n",
    "    print('PROCESSING INDEX FILE [{}]/[{}] ...'.format(i, len(file_dict)))\n",
    "    print('Downloading an index file {} ...'.format(file_name))\n",
    "    save(url, file_name)\n",
    "    process_index_file(file_name)\n",
    "    gc.collect()\n",
    "    # print(i,(file_name,url))\n",
    "    print('Downloaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:47:18.968282Z",
     "start_time": "2019-12-06T20:47:18.963274Z"
    }
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:47:22.893186Z",
     "start_time": "2019-12-06T20:47:22.886185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/index_paths/cc-index.paths'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:47:29.179095Z",
     "start_time": "2019-12-06T20:47:29.173099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/index_paths/cc-index.paths.feather'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:48:30.311815Z",
     "start_time": "2019-12-06T20:48:30.307812Z"
    }
   },
   "outputs": [],
   "source": [
    "df_name = file_name.split('/')[-1].replace('.gz', '.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:48:36.104957Z",
     "start_time": "2019-12-06T20:48:36.099953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc-index.paths.feather'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:45:57.273569Z",
     "start_time": "2019-12-06T20:45:57.233510Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/index_paths/cc-index.paths'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ff07693cc02e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile_unzipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf_in\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_unzipped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf_out\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/index_paths/cc-index.paths'"
     ]
    }
   ],
   "source": [
    "with gzip.open(file_name, 'rb') as f_in:\n",
    "    with open(file_unzipped, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

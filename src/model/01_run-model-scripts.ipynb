{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model.py\n",
      "\n",
      "Trains RandomForestClassifier model on <input> file located in\n",
      " ../../data/processed. Saves model to ../../models.\n",
      "\n",
      "Usage:\n",
      "    train_model.py <filename> [options]\n",
      "\n",
      "Options\n",
      "    -i --input <file>       Filename, with extension, but without path\n",
      "                            (../../data/processed). [default: train_df.feather]\n",
      "    -o --output <file>      Filename for resulting model, without extension.\n",
      "                            Will be save to ../../models/. [default: rf_model]\n",
      "    -h --help               Show docstring.\n",
      "    -t                      Test mode.\n"
     ]
    }
   ],
   "source": [
    "%run train_model.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test...\n",
      "['subdomain_null_ind', 'subdomain_www_ind', 'length_url', 'domain_dot_cnt', 'path_dot_cnt', 'hostname_dash_cnt', 'hostname_entropy', 'url_entropy', 'php_ind', 'abuse_ind', 'admin_ind', 'verification_ind', 'length_path_frac_url_len', 'length_domain_frac_url_len', 'url_slash_cnt_frac_url_len', 'url_digit_cnt_frac_url_len', 'url_special_char_cnt_frac_url_len', 'url_reserved_char_cnt_frac_url_len']\n"
     ]
    }
   ],
   "source": [
    "%run train_model.py -t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Prepping data...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['length_path_frac_url_len', 'length_domain_frac_url_len', 'url_slash_cnt_frac_url_len', 'url_digit_cnt_frac_url_len', 'url_special_char_cnt_frac_url_len', 'url_reserved_char_cnt_frac_url_len']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/data_science/Projects/phishing-urls/src/model/train_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/data_science/Projects/phishing-urls/src/model/train_model.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(input_file, output_file, model_cols)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prepping data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/data_science/Projects/phishing-urls/src/util.py\u001b[0m in \u001b[0;36mprep_for_model\u001b[0;34m(df, model_cols)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mmodel_cols\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mare\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdrop\u001b[0m \u001b[0mna\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     '''\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mint_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0mint_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mint_cols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_ind'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[1;32m   4283\u001b[0m                 \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4284\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4285\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4286\u001b[0m                 \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ['length_path_frac_url_len', 'length_domain_frac_url_len', 'url_slash_cnt_frac_url_len', 'url_digit_cnt_frac_url_len', 'url_special_char_cnt_frac_url_len', 'url_reserved_char_cnt_frac_url_len']"
     ]
    }
   ],
   "source": [
    "%run train_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import re\n",
    "import feather\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from docopt import docopt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion, make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "project_dir = os.path.dirname(os.path.dirname(os.path.abspath(os.path.curdir)))\n",
    "# project_dir = os.path.dirname(os.path.abspath(os.path.curdir))\n",
    "new_path = os.path.join(project_dir, 'src')\n",
    "sys.path.append(new_path)\n",
    "\n",
    "import util as u\n",
    "from model import pipeline as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'train_df.feather'\n",
    "input_path = os.path.join('../../data/processed/', input_file)\n",
    "df = feather.read_dataframe(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = df.select_dtypes(include='int').columns\n",
    "int_cols = [col for col in int_cols if re.search('_ind', col) is None]\n",
    "\n",
    "for col in int_cols:\n",
    "    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "cols_to_convert = ['length_path', 'length_domain', 'url_slash_cnt',\n",
    "                    'url_digit_cnt', 'url_special_char_cnt',\n",
    "                    'url_reserved_char_cnt']\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    new_col_name = col + '_frac_url_len'\n",
    "    df[new_col_name] = df[col] / df['length_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = ['subdomain_null_ind', 'subdomain_www_ind', 'length_url',\n",
    "              'domain_dot_cnt', 'path_dot_cnt', 'hostname_dash_cnt',\n",
    "              'hostname_entropy', 'url_entropy', 'php_ind', 'abuse_ind',\n",
    "              'admin_ind','verification_ind',\n",
    "              'length_path_frac_url_len', 'length_domain_frac_url_len',\n",
    "              'url_slash_cnt_frac_url_len', 'url_digit_cnt_frac_url_len',\n",
    "              'url_special_char_cnt_frac_url_len', 'url_reserved_char_cnt_frac_url_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=model_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pipeline ready...\n",
      "Fitting model....\n"
     ]
    }
   ],
   "source": [
    "target = 'label'\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "all_cols = df.columns\n",
    "\n",
    "# Preprocessing\n",
    "print('Getting pipeline ready...')\n",
    "proc_dict = {\n",
    "#     'base_suffix':[p.Consolidate(1), OneHotEncoder(handle_unknown='ignore')]\n",
    "            }\n",
    "\n",
    "num_cols = [col for col in all_cols if re.search('_cnt', col) is not None] + \\\n",
    "            ['length_url', 'hostname_entropy', 'url_entropy']\n",
    "\n",
    "bool_cols = [col for col in all_cols if re.search('_ind', col) is not None]\n",
    "\n",
    "pass_thru_cols = [col for col in all_cols if re.search('_frac_url_len', col) is not None]\n",
    "\n",
    "for col in num_cols:\n",
    "    proc_dict[col] = [StandardScaler()]\n",
    "\n",
    "for col in bool_cols + pass_thru_cols:\n",
    "    proc_dict[col] = [p.PassThrough()]\n",
    "\n",
    "# Pipeline\n",
    "preproc_pipe = FeatureUnion(p.gen_pipeline(model_cols, proc_dict))\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10, criterion='entropy')\n",
    "pipe = make_pipeline(preproc_pipe, clf)\n",
    "\n",
    "print('Fitting model....')\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicting train...')\n",
    "y_pred = pipe.predict(X)\n",
    "score = f1_score(y, y_pred)\n",
    "print('Training score: ', score)\n",
    "\n",
    "print('Saving model...')\n",
    "outputh_path = os.path.join('../../models/', output_file)\n",
    "joblib.dump(pipe, output_path)\n",
    "\n",
    "u.pickle_this(y_pred, '../../data/processed/train_pred.pkl')\n",
    "print('Script complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
